{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, FastICA as ICA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, mutual_info_classif\n",
    "from sklearn.random_projection import GaussianRandomProjection as GRP\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv(\"./assets/cleaned_student_data.csv\")\n",
    "X_student = df_main.iloc[:, :-1].astype('float')\n",
    "y_student = df_main.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv(\"./assets/cleaned_housing_data.csv\")\n",
    "X_housing = df_main.iloc[:, :-1].astype('float')\n",
    "y_housing = df_main.iloc[:, -1]\n",
    "re_label = dict(zip(y_housing.unique()[::-1], range(y_housing.unique().size)))  # convert 'Group x' to int\n",
    "y_housing = y_housing.replace(re_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_decorator_km(func):\n",
    "    def benchmark(X, y, comp, n_class, title, n_iterations):\n",
    "        df_results = pd.DataFrame(index=range(n_iterations), columns=['acc', 'nmi'])\n",
    "        \n",
    "        for iteration in range(n_iterations):\n",
    "            X_trans = func(X, comp)\n",
    "            preds = KMeans(n_class, n_jobs=-1).fit_predict(X_trans)\n",
    "            acc = accuracy_score(preds, y)\n",
    "            nmi = NMI(preds, y)\n",
    "            \n",
    "            df_results.loc[iteration, 'acc'] = acc\n",
    "            df_results.loc[iteration, 'nmi'] = nmi\n",
    "        \n",
    "        mean = df_results.mean(0)\n",
    "        std = df_results.std(0)\n",
    "        df_stats = pd.DataFrame(index=['mean', 'std'],\n",
    "                                columns=['acc', 'nmi'],\n",
    "                                data=np.vstack([mean, std]))\n",
    "        \n",
    "        df_results = pd.concat([df_results, df_stats], axis=0)\n",
    "        df_results.index.name = \"N_components: \" + title\n",
    "        return df_results\n",
    "    return benchmark\n",
    "\n",
    "def benchmark_decorator_km_fs(func):\n",
    "    def benchmark(X, y, comp, n_class, title, n_iterations):\n",
    "        df_results = pd.DataFrame(index=range(n_iterations), columns=['acc', 'nmi'])\n",
    "        \n",
    "        for iteration in range(n_iterations):\n",
    "            X_trans = func(X, y, comp)\n",
    "            preds = KMeans(n_class, n_jobs=-1).fit_predict(X_trans)\n",
    "            acc = accuracy_score(preds, y)\n",
    "            nmi = NMI(preds, y)\n",
    "            \n",
    "            df_results.loc[iteration, 'acc'] = acc\n",
    "            df_results.loc[iteration, 'nmi'] = nmi\n",
    "        \n",
    "        mean = df_results.mean(0)\n",
    "        std = df_results.std(0)\n",
    "        df_stats = pd.DataFrame(index=['mean', 'std'],\n",
    "                                columns=['acc', 'nmi'],\n",
    "                                data=np.vstack([mean, std]))\n",
    "        \n",
    "        df_results = pd.concat([df_results, df_stats], axis=0)\n",
    "        df_results.index.name = \"N_components: \" + title\n",
    "        return df_results\n",
    "    return benchmark\n",
    "\n",
    "def benchmark_decorator_em(func):\n",
    "    def benchmark(X, y, comp, n_class, title, n_iterations):\n",
    "        df_results = pd.DataFrame(index=range(n_iterations), columns=['acc', 'nmi'])\n",
    "        \n",
    "        for iteration in range(n_iterations):\n",
    "            X_trans = func(X, comp)\n",
    "            gmm = GMM(n_class)\n",
    "            gmm.fit(X_trans)\n",
    "            preds = gmm.predict(X_trans)\n",
    "            acc = accuracy_score(preds, y)\n",
    "            nmi = NMI(preds, y)\n",
    "            \n",
    "            df_results.loc[iteration, 'acc'] = acc\n",
    "            df_results.loc[iteration, 'nmi'] = nmi\n",
    "        \n",
    "        mean = df_results.mean(0)\n",
    "        std = df_results.std(0)\n",
    "        df_stats = pd.DataFrame(index=['mean', 'std'],\n",
    "                                columns=['acc', 'nmi'],\n",
    "                                data=np.vstack([mean, std]))\n",
    "        \n",
    "        df_results = pd.concat([df_results, df_stats], axis=0)\n",
    "        df_results.index.name = \"N_components: \" + title\n",
    "        return df_results\n",
    "    return benchmark\n",
    "\n",
    "def benchmark_decorator_em_fs(func):\n",
    "    def benchmark(X, y, comp, n_class, title, n_iterations):\n",
    "        df_results = pd.DataFrame(index=range(n_iterations), columns=['acc', 'nmi'])\n",
    "        \n",
    "        for iteration in range(n_iterations):\n",
    "            X_trans = func(X, y, comp)\n",
    "            gmm = GMM(n_class)\n",
    "            gmm.fit(X_trans)\n",
    "            preds = gmm.predict(X_trans)\n",
    "            acc = accuracy_score(preds, y)\n",
    "            nmi = NMI(preds, y)\n",
    "            \n",
    "            df_results.loc[iteration, 'acc'] = acc\n",
    "            df_results.loc[iteration, 'nmi'] = nmi\n",
    "        \n",
    "        mean = df_results.mean(0)\n",
    "        std = df_results.std(0)\n",
    "        df_stats = pd.DataFrame(index=['mean', 'std'],\n",
    "                                columns=['acc', 'nmi'],\n",
    "                                data=np.vstack([mean, std]))\n",
    "        \n",
    "        df_results = pd.concat([df_results, df_stats], axis=0)\n",
    "        df_results.index.name = \"N_components: \" + title\n",
    "        return df_results\n",
    "    return benchmark\n",
    "\n",
    "@benchmark_decorator_km\n",
    "def perform_pca_km(X, comps, *args):\n",
    "    transformer = PCA(n_components=comps, random_state=7308)\n",
    "    return transformer.fit_transform(X)\n",
    "\n",
    "\n",
    "@benchmark_decorator_km\n",
    "def perform_ica_km(X, comps, *args):\n",
    "    transformer = ICA(n_components=comps, random_state=7308)\n",
    "    return transformer.fit_transform(X)\n",
    "\n",
    "\n",
    "@benchmark_decorator_km\n",
    "def perform_grp_km(X, comps, *args):\n",
    "    transformer = GRP(n_components=comps, random_state=7308)\n",
    "    return transformer.fit_transform(X)\n",
    "\n",
    "\n",
    "@benchmark_decorator_km\n",
    "def perform_tsne_km(X, comps):\n",
    "    transformer = TSNE(n_components=2, init='pca', random_state=7308)\n",
    "    return transformer.fit_transform(X)\n",
    "\n",
    "\n",
    "@benchmark_decorator_km_fs\n",
    "def perform_gus_km(X, y, comps):\n",
    "    transformer = GenericUnivariateSelect(mutual_info_classif, mode='k_best', param=comps)\n",
    "    return transformer.fit_transform(X, y)\n",
    "\n",
    "\n",
    "@benchmark_decorator_em\n",
    "def perform_pca_em(X, comps, *args):\n",
    "    transformer = PCA(n_components=comps, random_state=7308)\n",
    "    return transformer.fit_transform(X)\n",
    "\n",
    "\n",
    "@benchmark_decorator_em\n",
    "def perform_ica_em(X, comps, *args):\n",
    "    transformer = ICA(n_components=comps, random_state=7308)\n",
    "    return transformer.fit_transform(X)\n",
    "\n",
    "\n",
    "@benchmark_decorator_em\n",
    "def perform_grp_em(X, comps, *args):\n",
    "    transformer = GRP(n_components=comps, random_state=7308)\n",
    "    return transformer.fit_transform(X)\n",
    "\n",
    "\n",
    "@benchmark_decorator_em_fs\n",
    "def perform_gus_em(X, y, comps):\n",
    "    transformer = GenericUnivariateSelect(mutual_info_classif, mode='k_best', param=comps)\n",
    "    return transformer.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KM benchmark data for student\n",
    "\n",
    "save_path = \"./assets/results_base/student\"\n",
    "iterations = 10\n",
    "scaler = StandardScaler()\n",
    "X_std, y = scaler.fit_transform(X_student), y_student\n",
    "\n",
    "for comp in range(2, 16):\n",
    "    df_pca = perform_pca_km(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "    df_ica = perform_pca_km(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "    df_grp = perform_grp_km(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "    df_gus = perform_gus_km(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "\n",
    "    df_pca.to_csv(\"{}/km_PCA/components_{}.csv\".format(save_path, comp))\n",
    "    df_ica.to_csv(\"{}/km_ICA/components_{}.csv\".format(save_path, comp))\n",
    "    df_grp.to_csv(\"{}/km_GRP/components_{}.csv\".format(save_path, comp))\n",
    "    df_gus.to_csv(\"{}/km_GUS/components_{}.csv\".format(save_path, comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KM benchmark data for housing\n",
    "\n",
    "save_path = \"./assets/results_base/housing\"\n",
    "iterations = 5\n",
    "scaler = StandardScaler()\n",
    "X_std, y = scaler.fit_transform(X_housing), y_housing\n",
    "\n",
    "for comp in range(2, 25):\n",
    "    df_pca = perform_pca_km(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "    df_ica = perform_pca_km(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "    df_grp = perform_grp_km(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "    df_gus = perform_gus_km(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "\n",
    "    df_pca.to_csv(\"{}/km_PCA/components_{}.csv\".format(save_path, comp))\n",
    "    df_ica.to_csv(\"{}/km_ICA/components_{}.csv\".format(save_path, comp))\n",
    "    df_grp.to_csv(\"{}/km_GRP/components_{}.csv\".format(save_path, comp))\n",
    "    df_gus.to_csv(\"{}/km_GUS/components_{}.csv\".format(save_path, comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EM benchmark data for student\n",
    "\n",
    "save_path = \"./assets/results_base/student\"\n",
    "iterations = 10\n",
    "scaler = StandardScaler()\n",
    "X_std, y = scaler.fit_transform(X_student), y_student\n",
    "\n",
    "for comp in range(2, 16):\n",
    "    df_pca = perform_pca_em(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "    df_ica = perform_pca_em(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "    df_grp = perform_grp_em(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "    df_gus = perform_gus_em(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "\n",
    "    df_pca.to_csv(\"{}/em_PCA/components_{}.csv\".format(save_path, comp))\n",
    "    df_ica.to_csv(\"{}/em_ICA/components_{}.csv\".format(save_path, comp))\n",
    "    df_grp.to_csv(\"{}/em_GRP/components_{}.csv\".format(save_path, comp))\n",
    "    df_gus.to_csv(\"{}/em_GUS/components_{}.csv\".format(save_path, comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EM benchmark data for housing\n",
    "\n",
    "save_path = \"./assets/results_base/housing\"\n",
    "iterations = 5\n",
    "scaler = StandardScaler()\n",
    "X_std, y = scaler.fit_transform(X_housing), y_housing\n",
    "\n",
    "for comp in range(2, 25):\n",
    "    df_pca = perform_pca_em(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "    df_ica = perform_pca_em(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "    df_grp = perform_grp_em(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "    df_gus = perform_gus_em(X_std, y, comp, n_class=y.nunique(), title=str(comp), n_iterations=iterations)\n",
    "\n",
    "    df_pca.to_csv(\"{}/em_PCA/components_{}.csv\".format(save_path, comp))\n",
    "    df_ica.to_csv(\"{}/em_ICA/components_{}.csv\".format(save_path, comp))\n",
    "    df_grp.to_csv(\"{}/em_GRP/components_{}.csv\".format(save_path, comp))\n",
    "    df_gus.to_csv(\"{}/em_GUS/components_{}.csv\".format(save_path, comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate km benchmark data for student\n",
    "\n",
    "file_path = \"./assets/results_base/student\"\n",
    "results = []\n",
    "for base in glob.glob(file_path + \"/km_*\"):\n",
    "    transformer = base.split(\"/\")[-1]\n",
    "    df_results = pd.DataFrame()\n",
    "    for i,f in zip(range(2, 25), glob.glob(\"{}/{}/*.csv\".format(file_path, transformer))):\n",
    "        n_comps = f.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "        n_comps = n_comps.zfill(2)\n",
    "\n",
    "        df_temp = pd.read_csv(f, usecols=['acc', 'nmi'])\n",
    "        df_temp.rename(columns={'acc':'{}_acc'.format(n_comps), 'nmi':'{}_nmi'.format(n_comps)}, inplace=True)\n",
    "        df_results = pd.concat([df_results, df_temp], axis=1)\n",
    "\n",
    "    orig_cols = list(range(df_temp.shape[0]))\n",
    "    orig_cols[-2] = 'mean'\n",
    "    orig_cols[-1] = 'std'\n",
    "\n",
    "    df_results.index = orig_cols\n",
    "    df_results.index.name = transformer\n",
    "    df_results = df_results.reindex(sorted(df_results.columns), axis=1)\n",
    "    \n",
    "    results.append(df_results)\n",
    "    \n",
    "highest_value = 0\n",
    "highest_index = None\n",
    "transformer = None\n",
    "\n",
    "for result in results:\n",
    "    accuracies = result.filter(regex='acc', axis=1)\n",
    "    nmis = result.filter(regex='nmi', axis=1)\n",
    "    \n",
    "    highest_acc = accuracies.loc['mean', :].max()\n",
    "    high_acc_index = accuracies.loc['mean', :].idxmax()\n",
    "    high_acc_std = accuracies.loc['std', high_acc_index]\n",
    "\n",
    "    highest_nmi = nmis.loc['mean', :].max()\n",
    "    high_nmi_index = nmis.loc['mean', :].idxmax()\n",
    "    high_nmi_std = nmis.loc['std', high_nmi_index]\n",
    "    \n",
    "    transformer_ = result.index.name\n",
    "    \n",
    "    print(\"{} achieved a highest accuracy of {:.4f}\\u00B1{:.4f} with n_comps: {}\"\n",
    "      .format(transformer_, highest_acc, high_acc_std, high_acc_index.split(\"_\")[0]))\n",
    "\n",
    "    print(\"{} achieved a highest NMI of {:.4f}\\u00B1{:.5f} with n_comps: {}\"\n",
    "      .format(transformer_, highest_nmi, high_nmi_std, high_nmi_index.split(\"_\")[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate EM benchmark data for student\n",
    "file_path = \"./assets/results_base/student\"\n",
    "results = []\n",
    "for base in glob.glob(file_path + \"/em_*\"):\n",
    "    transformer = base.split(\"/\")[-1]\n",
    "    df_results = pd.DataFrame()\n",
    "    for i,f in zip(range(2, 25), glob.glob(\"{}/{}/*.csv\".format(file_path, transformer))):\n",
    "        n_comps = f.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "        n_comps = n_comps.zfill(2)\n",
    "\n",
    "        df_temp = pd.read_csv(f, usecols=['acc', 'nmi'])\n",
    "        df_temp.rename(columns={'acc':'{}_acc'.format(n_comps), 'nmi':'{}_nmi'.format(n_comps)}, inplace=True)\n",
    "        df_results = pd.concat([df_results, df_temp], axis=1)\n",
    "\n",
    "    orig_cols = list(range(df_temp.shape[0]))\n",
    "    orig_cols[-2] = 'mean'\n",
    "    orig_cols[-1] = 'std'\n",
    "\n",
    "    df_results.index = orig_cols\n",
    "    df_results.index.name = transformer\n",
    "    df_results = df_results.reindex(sorted(df_results.columns), axis=1)\n",
    "    \n",
    "    results.append(df_results)\n",
    "    \n",
    "highest_value = 0\n",
    "highest_index = None\n",
    "transformer = None\n",
    "\n",
    "for result in results:\n",
    "    accuracies = result.filter(regex='acc', axis=1)\n",
    "    nmis = result.filter(regex='nmi', axis=1)\n",
    "    \n",
    "    highest_acc = accuracies.loc['mean', :].max()\n",
    "    high_acc_index = accuracies.loc['mean', :].idxmax()\n",
    "    high_acc_std = accuracies.loc['std', high_acc_index]\n",
    "\n",
    "    highest_nmi = nmis.loc['mean', :].max()\n",
    "    high_nmi_index = nmis.loc['mean', :].idxmax()\n",
    "    high_nmi_std = nmis.loc['std', high_nmi_index]\n",
    "    \n",
    "    transformer_ = result.index.name\n",
    "    \n",
    "    print(\"{} achieved a highest accuracy of {:.4f}\\u00B1{:.4f} with n_comps: {}\"\n",
    "      .format(transformer_, highest_acc, high_acc_std, high_acc_index.split(\"_\")[0]))\n",
    "\n",
    "    print(\"{} achieved a highest NMI of {:.4f}\\u00B1{:.5f} with n_comps: {}\"\n",
    "      .format(transformer_, highest_nmi, high_nmi_std, high_nmi_index.split(\"_\")[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate km benchmark data for housing\n",
    "file_path = \"./assets/results_base/housing\"\n",
    "results = []\n",
    "for base in glob.glob(file_path + \"/km_*\"):\n",
    "    transformer = base.split(\"/\")[-1]\n",
    "    df_results = pd.DataFrame()\n",
    "    for i,f in zip(range(2, 25), glob.glob(\"{}/{}/*.csv\".format(file_path, transformer))):\n",
    "        n_comps = f.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "        n_comps = n_comps.zfill(2)\n",
    "\n",
    "        df_temp = pd.read_csv(f, usecols=['acc', 'nmi'])\n",
    "        df_temp.rename(columns={'acc':'{}_acc'.format(n_comps), 'nmi':'{}_nmi'.format(n_comps)}, inplace=True)\n",
    "        df_results = pd.concat([df_results, df_temp], axis=1)\n",
    "\n",
    "    orig_cols = list(range(df_temp.shape[0]))\n",
    "    orig_cols[-2] = 'mean'\n",
    "    orig_cols[-1] = 'std'\n",
    "\n",
    "    df_results.index = orig_cols\n",
    "    df_results.index.name = transformer\n",
    "    df_results = df_results.reindex(sorted(df_results.columns), axis=1)\n",
    "    \n",
    "    results.append(df_results)\n",
    "\n",
    "highest_value = 0\n",
    "highest_index = None\n",
    "transformer = None\n",
    "\n",
    "for result in results:\n",
    "    accuracies = result.filter(regex='acc', axis=1)\n",
    "    nmis = result.filter(regex='nmi', axis=1)\n",
    "    \n",
    "    highest_acc = accuracies.loc['mean', :].max()\n",
    "    high_acc_index = accuracies.loc['mean', :].idxmax()\n",
    "    high_acc_std = accuracies.loc['std', high_acc_index]\n",
    "\n",
    "    highest_nmi = nmis.loc['mean', :].max()\n",
    "    high_nmi_index = nmis.loc['mean', :].idxmax()\n",
    "    high_nmi_std = nmis.loc['std', high_nmi_index]\n",
    "    \n",
    "    transformer_ = result.index.name\n",
    "    \n",
    "    print(\"{} achieved a highest accuracy of {:.4f}\\u00B1{:.4f} with n_comps: {}\"\n",
    "      .format(transformer_, highest_acc, high_acc_std, high_acc_index.split(\"_\")[0]))\n",
    "\n",
    "    print(\"{} achieved a highest NMI of {:.4f}\\u00B1{:.5f} with n_comps: {}\"\n",
    "      .format(transformer_, highest_nmi, high_nmi_std, high_nmi_index.split(\"_\")[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate EM benchmark data for housing\n",
    "file_path = \"./assets/results_base/housing\"\n",
    "results = []\n",
    "for base in glob.glob(file_path + \"/em_*\"):\n",
    "    transformer = base.split(\"/\")[-1]\n",
    "    df_results = pd.DataFrame()\n",
    "    for i,f in zip(range(2, 25), glob.glob(\"{}/{}/*.csv\".format(file_path, transformer))):\n",
    "        n_comps = f.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "        n_comps = n_comps.zfill(2)\n",
    "\n",
    "        df_temp = pd.read_csv(f, usecols=['acc', 'nmi'])\n",
    "        df_temp.rename(columns={'acc':'{}_acc'.format(n_comps), 'nmi':'{}_nmi'.format(n_comps)}, inplace=True)\n",
    "        df_results = pd.concat([df_results, df_temp], axis=1)\n",
    "\n",
    "    orig_cols = list(range(df_temp.shape[0]))\n",
    "    orig_cols[-2] = 'mean'\n",
    "    orig_cols[-1] = 'std'\n",
    "\n",
    "    df_results.index = orig_cols\n",
    "    df_results.index.name = transformer\n",
    "    df_results = df_results.reindex(sorted(df_results.columns), axis=1)\n",
    "    \n",
    "    results.append(df_results)\n",
    "\n",
    "highest_value = 0\n",
    "highest_index = None\n",
    "transformer = None\n",
    "\n",
    "for result in results:\n",
    "    accuracies = result.filter(regex='acc', axis=1)\n",
    "    nmis = result.filter(regex='nmi', axis=1)\n",
    "    \n",
    "    highest_acc = accuracies.loc['mean', :].max()\n",
    "    high_acc_index = accuracies.loc['mean', :].idxmax()\n",
    "    high_acc_std = accuracies.loc['std', high_acc_index]\n",
    "\n",
    "    highest_nmi = nmis.loc['mean', :].max()\n",
    "    high_nmi_index = nmis.loc['mean', :].idxmax()\n",
    "    high_nmi_std = nmis.loc['std', high_nmi_index]\n",
    "    \n",
    "    transformer_ = result.index.name\n",
    "    \n",
    "    print(\"{} achieved a highest accuracy of {:.4f}\\u00B1{:.4f} with n_comps: {}\"\n",
    "      .format(transformer_, highest_acc, high_acc_std, high_acc_index.split(\"_\")[0]))\n",
    "\n",
    "    print(\"{} achieved a highest NMI of {:.4f}\\u00B1{:.5f} with n_comps: {}\"\n",
    "      .format(transformer_, highest_nmi, high_nmi_std, high_nmi_index.split(\"_\")[0]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
